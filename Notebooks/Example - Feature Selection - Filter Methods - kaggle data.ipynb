{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection**\n",
    "Here we explore methodologies to identify which features are useful provide a higher predictive power to the model. Given a dataset, a model trained on it can depend on features directly on derived features. How do we tell wich features are the most useful? Multiple approaches exist, which are based on simple ideas of univariate analysis to complex multivariate analysis. In univariate analysis we look at how a single feature contribute to the model. Although useful, it does have pitfalls as some features are better together. In multivariate analysis we can tell which features perform well and more importantly which perform well together. Various techniques exist driven differentiated by how information is extracted. When data contains label like the case here, we use supervised techniques, nevetheless, unsupervised techniques can be used for unlabelled data.\n",
    "\n",
    "Collaborative filtering is built on the assumption that a good way to predict the\n",
    "preference of an active consumer for a target product is to find other consumers\n",
    "who have similar preferences and use their votes for that product to make a\n",
    "prediction.\n",
    "As noted in the [source page](https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/), these techniques can be classified as follows\n",
    "- **Filter methods:** based on features properties highlighted via univariate analysis\n",
    "\n",
    "- **Wrapper methods:** With a specific learning algorithm, these methose can perform a greedy search of the best feature by fitting models with possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. \n",
    "- **Embedded methods:** Here they aim to combine the power of both filters and wrapper while maintaining reasonable computational cost.\n",
    "- **Hybrid method:** Hybrid methods basically select features via a global transformation reduces the data to a desided number of dimensions. The new features can bear little or no resemblance to the initial features.\n",
    "\n",
    "Libraries used in the notebook:\n",
    "* [pandas](https://pandas.pydata.org/docs/),\n",
    "* [scikit-learn](https://scikit-learn.org/stable/),\n",
    "* [optbinning](https://github.com/guillermo-navas-palencia/optbinning),\n",
    "* [sklearn.feature_selection](https://scikit-learn.org/stable/modules/feature_selection.html),\n",
    "* [Category encoding](https://contrib.scikit-learn.org/category_encoders/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from optbinning import BinningProcess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'kaggle-data.pkl', 'rb') as f:\n",
    "    df_application = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df_application.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format columns to lower case (just for a nice look :) )\n",
    "df_application.columns = [col.lower() for col in df_application.columns]\n",
    "df_application.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Filter methods\n",
    "Filter methods are based of techniques that uses univariate analysis. The ones covered here can be used for any model, so they are model agnostic. These filter methods includes\n",
    " - Information Value\n",
    " - Information Gain\n",
    " - Chi-square Test\n",
    " - Fisherâ€™s Score\n",
    " - Correlation Coefficient\n",
    " - Variance Threshold\n",
    " - AUC\n",
    "\n",
    "Those we noted that can also be used but we didn't explore includes\n",
    "- Mean Absolute Difference (MAD)\n",
    "- Dispersion ratio\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.1 Information Value (IV)\n",
    "Here we will explore the use of opbinning to the informational value. We will use the `BinningProcess` class from `optbinning` to get the optimal bins and the corresponding scoores.\n",
    "$$IV = \\sum{(\\% nonevent- \\% event)}*WOE, \\text{ with } WOE=ln(\\% nonevent/ \\% event)$$\n",
    "\n",
    "The table belows shows intepretations from N. Siddiqi's book.\n",
    "| Informational Value | Predictive Power |\n",
    "| --- | --- |\n",
    "| <0.02 | Useless for prediction | \n",
    "| 0.02-0.1 | Weak prediction | \n",
    "| 0.1-0.3 | Medium prediction | \n",
    "| 0.3-0.5 | Strong prediction |\n",
    "| >0.5 | Suspecious(Too good to be true) | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import OptimalBinning, BinningProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the `BinningProcess` with feature names and the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = df_application.columns[1:].to_list()\n",
    "binning_process = BinningProcess(select_cols)\n",
    "binning_process.fit(df_application[select_cols], df_application.target)\n",
    "binning_table = binning_process.summary()\n",
    "binning_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table[binning_table['name']=='ext_source_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a function that gets the summary table for Information Values, Jensen-Shannon entropy, Gini and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x, y):\n",
    "    select_cols = x.columns.to_list()\n",
    "    binning_process = BinningProcess(select_cols)\n",
    "    binning_process.fit(x, y)\n",
    "    binning_table = binning_process.summary()\n",
    "    binning_table.sort_values(by='iv', inplace=True, ascending=False)\n",
    "    binning_table['interpretation'] = binning_table['iv'].apply(interpretation)\n",
    "    return binning_table\n",
    "\n",
    "def interpretation(iv):\n",
    "    if iv < 0.02:\n",
    "        return 'useless'\n",
    "    elif iv < 0.1:\n",
    "        return 'weak'\n",
    "    elif iv < 0.3:\n",
    "        return 'medium'\n",
    "    elif iv < 0.5:\n",
    "        return 'strong'\n",
    "    else:\n",
    "        return 'suspicious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics = get_metrics(df_application[select_cols], df_application.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics[binning_table_metrics['interpretation'].isin(['strong', 'medium'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variance threshold\n",
    "Here we remove the data with smaller variance. For simplicity we will start using just numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with numerical data\n",
    "X = df_application.drop('target', axis=1)\n",
    "Y = df_application.target\n",
    "numerical_columns = X.select_dtypes(include=np.number).columns.values\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Categorical variables. For now, lets used  TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder()\n",
    "X_cat = encoder.fit_transform(X[categorical_columns], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[categorical_columns] = X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_threshold = feature_selection.VarianceThreshold(threshold=0.001)\n",
    "constant_threshold.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced features is\n",
    "# df_application_train, df_application_test, y_train, y_test\n",
    "X_filter = constant_threshold.transform(X)\n",
    "# X_tfilter = constant_threshold.transform(df_application_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = selector.get_support(indices=True)\n",
    "selected_columns = X.iloc[:,cols].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Information gain\n",
    "Here we will use the mutual information to streamline the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = X.columns[constant_threshold.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = feature_selection.mutual_info_classif(X[select_features].fillna(X[select_features].mean()), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(importance, select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.sort_values(ascending=False).head(10).plot(kind='barh', color='teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides functionality to automatically select features when a measure and selection criteria are provided. In this case, we can use selection pipeline and metrics like `Percentile`, or top best, to select a particular number of columns. Scikit-learn untitilites for this includes\n",
    "- [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile)\n",
    "- [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "\n",
    "These can be used with measures like mutual information (`mutual_info_classif`), Chi Square (`chi2`), Fisher information etc. We will demonstrate for mutual information. Note that this takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel = feature_selection.SelectPercentile(\n",
    "#     feature_selection.mutual_info_classif,\n",
    "#     percentile=10\n",
    "# ).fit(X_filter, Y)\n",
    "# X_filter.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 AUC\n",
    "AUC is good measure for model performance for various reasons. Here we want to use AUC to measure the performance of a model build on a single feature. At the end we select features with high AUC. This is a model based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = X[select_features].fillna(X[select_features].mean())\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = []\n",
    "for feature in numerical_columns:\n",
    "    clf = LogisticRegression(max_iter=100, random_state=42)\n",
    "    clf.fit(X[feature].fillna(0).values.reshape(-1, 1), Y)\n",
    "    y_pred = clf.predict(X_test[feature].fillna(0).values.reshape(-1, 1))\n",
    "    roc_auc.append(metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_series = pd.Series(roc_auc, index=numerical_columns).sort_values(ascending=False)\n",
    "roc_auc_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any feature with AUC < 0.5 are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_series[roc_auc_series>0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then used this to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg(X_train, y_train, X_test, y_test):\n",
    "    clf =  LogisticRegression(C=3, max_iter=100, random_state=42)\n",
    "    clf.fit(X_train.fillna(0), y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy on test set is: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "s = roc_auc_series[roc_auc_series>0.5].index.to_list()\n",
    "run_logreg(X[numerical_columns], Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Correlation coefficients.\n",
    "This can be a quick and easy way to see which features are correlated with the target. Correlation compute the Perason Correlation, the logic behind its used for feature selection is that the good variables are highly correlated with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of plotting we will only select 10 features\n",
    "correlation_matrix = X[numerical_columns[:10]].merge(Y, right_index=True, left_index=True).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 F-Test\n",
    "This uses the F statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kbest_features(X, y, metric, k=5):\n",
    "\n",
    "    selector = feature_selection.SelectKBest(metric)\n",
    "    X_reduced = selector.fit_transform(X, y)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    selected_columns = processed_data.iloc[:,cols].columns.tolist()\n",
    "\n",
    "    return  selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_feature_importance(\n",
    "    X.fillna(0), \n",
    "    Y, \n",
    "    metric=feature_selection.f_classif, \n",
    "    k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Chi-square Test\n",
    "This uses the Chi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_feature_importance(\n",
    "    X.fillna(0), \n",
    "    Y, \n",
    "    metric=feature_selection.chi2, \n",
    "    k=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fd63eb72525a75257cc516a0cfc39ada6c8fb7c5880648d875123d43420ed6b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('scorecard': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
