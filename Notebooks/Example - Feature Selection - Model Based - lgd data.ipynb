{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection**\n",
    "Here we explore methodologies to identify which features are useful provide a higher predictive power to the model. Given a dataset, a model trained on it can depend on features directly on derived features. How do we tell wich features are the most useful? Multiple approaches exist, which are based on simple ideas of univariate analysis to complex multivariate analysis. In univariate analysis we look at how a single feature contribute to the model. Although useful, it does have pitfalls as some features are better together. In multivariate analysis we can tell which features perform well and more importantly which perform well together. Various techniques exist driven differentiated by how information is extracted. When data contains label like the case here, we use supervised techniques, nevetheless, unsupervised techniques can be used for unlabelled data.\n",
    "\n",
    "Collaborative filtering is built on the assumption that a good way to predict the\n",
    "preference of an active consumer for a target product is to find other consumers\n",
    "who have similar preferences and use their votes for that product to make a\n",
    "prediction.\n",
    "As noted in the [source page](https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/), these techniques can be classified as follows\n",
    "- **Filter methods:** based on features properties highlighted via univariate analysis\n",
    "\n",
    "- **Wrapper methods:** With a specific learning algorithm, these methose can perform a greedy search of the best feature by fitting models with possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. \n",
    "- **Embedded methods:** Here they aim to combine the power of both filters and wrapper while maintaining reasonable computational cost.\n",
    "- **Hybrid method:** Hybrid methods basically select features via a global transformation reduces the data to a desided number of dimensions. The new features can bear little or no resemblance to the initial features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:path', 'rb') as f:\n",
    "    df_application = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df_application.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import OptimalBinning, BinningProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format columns to lower case (just for a nice look :) )\n",
    "df_application.columns = [col.lower() for col in df_application.columns]\n",
    "df_application.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the `BinningProcess` with feature names and the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = df_application.columns[1:].to_list()\n",
    "binning_process = BinningProcess(select_cols)\n",
    "binning_process.fit(df_application[select_cols], df_application.target)\n",
    "binning_table = binning_process.summary()\n",
    "binning_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table[binning_table['name']=='ext_source_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a function that gets the summary table for Information Values, Jensen-Shannon entropy, Gini and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x, y):\n",
    "    select_cols = x.columns.to_list()\n",
    "    binning_process = BinningProcess(select_cols)\n",
    "    binning_process.fit(x, y)\n",
    "    binning_table = binning_process.summary()\n",
    "    binning_table.sort_values(by='iv', inplace=True, ascending=False)\n",
    "    binning_table['interpretation'] = binning_table['iv'].apply(interpretation)\n",
    "    return binning_table\n",
    "\n",
    "def interpretation(iv):\n",
    "    if iv < 0.02:\n",
    "        return 'useless'\n",
    "    elif iv < 0.1:\n",
    "        return 'weak'\n",
    "    elif iv < 0.3:\n",
    "        return 'medium'\n",
    "    elif iv < 0.5:\n",
    "        return 'strong'\n",
    "    else:\n",
    "        return 'suspicious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics = get_metrics(df_application[select_cols], df_application.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_table_metrics[binning_table_metrics['interpretation'].isin(['strong', 'medium'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variance threshold\n",
    "Here we remove the data with smaller variance. For simplicity we will start using just numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with numerical data\n",
    "X = df_application.drop('target', axis=1)\n",
    "Y = df_application.target\n",
    "numerical_columns = X.select_dtypes(include=np.number).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_threshold = feature_selection.VarianceThreshold(threshold=0.001)\n",
    "constant_threshold.fit(X[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced features is\n",
    "# df_application_train, df_application_test, y_train, y_test\n",
    "X_filter = constant_threshold.transform(X[numerical_columns])\n",
    "# X_tfilter = constant_threshold.transform(df_application_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[numerical_columns].columns[constant_threshold.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Information gain\n",
    "Here we will use the mutual information to streamline the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = X[numerical_columns].columns[constant_threshold.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = feature_selection.mutual_info_classif(X[select_features].fillna(X[select_features].mean()), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(importance, select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.sort_values(ascending=False).head(10).plot(kind='barh', color='teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides functionality to automatically select features when a measure and selection criteria are provided. In this case, we can use selection pipeline and metrics like `Percentile`, or top best, to select a particular number of columns. Scikit-learn untitilites for this includes\n",
    "- [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile)\n",
    "- [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "\n",
    "These can be used with measures like mutual information (`mutual_info_classif`), Chi Square (`chi2`), Fisher information etc. We will demonstrate for mutual information. Note that this takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel = feature_selection.SelectPercentile(\n",
    "#     feature_selection.mutual_info_classif,\n",
    "#     percentile=10\n",
    "# ).fit(X_filter, Y)\n",
    "# X_filter.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 AUC\n",
    "AUC is good measure for model performance for various reasons. Here we want to use AUC to measure the performance of a model build on a single feature. At the end we select features with high AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application = X[select_features].fillna(X[select_features].mean())\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = []\n",
    "for feature in numerical_columns:\n",
    "    clf = LogisticRegression(max_iter=100, random_state=42)\n",
    "    clf.fit(X[feature].fillna(0).values.reshape(-1, 1), Y)\n",
    "    y_pred = clf.predict(X_test[feature].fillna(0).values.reshape(-1, 1))\n",
    "    roc_auc.append(metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_series = pd.Series(roc_auc, index=numerical_columns).sort_values(ascending=False)\n",
    "roc_auc_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any feature with AUC < 0.5 are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_series[roc_auc_series>0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then used this to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg(X_train, y_train, X_test, y_test):\n",
    "    clf =  LogisticRegression(C=3, max_iter=100, random_state=42)\n",
    "    clf.fit(X_train.fillna(0), y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy on test set is: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "s = roc_auc_series[roc_auc_series>0.5].index.to_list()\n",
    "run_logreg(X[numerical_columns], Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Correlation coefficients.\n",
    "This can be a quick and easy way to see which features are correlated with the target. Correlation compute the Perason Correlation, the logic behind its used for feature selection is that the good variables are highly correlated with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of plotting we will only select 10 features\n",
    "correlation_matrix = X[numerical_columns[:10]].merge(Y, right_index=True, left_index=True).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3 Wrapper Methods:\n",
    "Wrappers require some method to search the space of all possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. The feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The wrapper methods usually result in better predictive accuracy than filter methods.\n",
    " - Forward Feature Selection\n",
    " - Backward Feature Elimination\n",
    " - Exhaustive Feature Selection\n",
    " - Recursive Feature Elimination\n",
    " \n",
    " Forward Feature Selection: Starts with the best and gradually adds the others\n",
    " Backward Feature Elimination: Starts will all and start elimicating, with worst the first to get out\n",
    " Exhaustive Feature Selection: Brute force method that searches each of the possible combinations\n",
    " \n",
    " We are going to address each of the methods, but for now will start with Recursive Feature Elimination as the others needs mlxtend library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Recursive Feature Elimination\n",
    "\n",
    "First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute.\n",
    "\n",
    "Then, the least important features are pruned from the current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe = feature_selection.RFE(\n",
    "    LogisticRegression(C=3, max_iter=1000, random_state=42),\n",
    "    n_features_to_select=10\n",
    ")\n",
    "rfe.fit(X[numerical_columns].fillna(X[numerical_columns].mean()), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4 Embedded Methods:\n",
    "The challenged we had in previous methods is that filters word with one feature, and wrapper selects a group of feature and then train the model from start to finish. The question is what if some features only present their power in some parameter space. Embedded methods are iterative in the sense that takes care of each iteration of the model training process and carefully extracts those features which contribute the most to the training for a particular iteration. [Read more here](https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LASSO Regularization\n",
    "Lasso methods applies regularization which can pernalize a feature differently and at different stages of the training interation process. Here we will use a `SelectFromModel` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X[numerical_columns].fillna(X[numerical_columns].mean())\n",
    "lrg = LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=1000, random_state=42)\n",
    "model = feature_selection.SelectFromModel(\n",
    "    lrg.fit(X_t, Y),\n",
    "    prefit=True\n",
    ")\n",
    "X_new = model.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest Importance\n",
    "Random Forest is an ensemble methods that builds many trees and a prediction is made by a concensus aggrement by multiple trees. The performance is measured by how well they improve the purity of the node using Gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_num, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the importance of the resulting features\n",
    "rf_imporatance_series = pd.Series(\n",
    "    rf.feature_importances_, \n",
    "    X_num.columns\n",
    "    ).sort_values(ascending=False)\n",
    "rf_imporatance_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_imporatance_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5 Global Methods:\n",
    " - Shapely values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SHAP Values\n",
    "SHAP Values (an acronym from SHapley Additive exPlanations) help in breaking down a prediction into components that illustrate the impact of each feature. This could be granular at the level of each instance (single row of data) or aggregated to see the models breakdown according to each feature. For some explanation see [here](https://www.kaggle.com/dansbecker/shap-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select numberical features\n",
    "feature_names = [i for i in data.columns if data[i].dtype in [np.int64, np.int64]]\n",
    "df_application = data[feature_names].fillna(0)\n",
    "train_X, val_X, train_y, val_y = train_test_split(df_application.drop('TARGET', axis=1), df_application['TARGET'], random_state=1)\n",
    "model = RandomForestClassifier(random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have a model, let's look at the prediction for a single row. Let's use row 3\n",
    "row_to_check = 3\n",
    "data_for_prediction = val_X.iloc[row_to_check:row_to_check+1]\n",
    "model.predict_proba(data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.iloc[row_to_check:row_to_check+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This customer is 91% likely to be a good customer according to the model. Now let's see is the main driver behind the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shap values above is a 2D array. First is the values for negtive outcome (bad customer) and the second the values for the positive outcome ( good  customer). Since we are looking at prediction of negative outcome we look at the second array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer2 = shap.Explainer(model)\n",
    "shap_values2 = explainer2(val_X.head(50))\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dependence scatter plot to show the effect of a single feature across the whole dataset\n",
    "shap.plots.scatter(shap_values2[:,\"RM\"], color=shap_values2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the explainer we us <code> shap.TreeExplainer() </code> as we have a tree. This is optimized to work for tree-base algorithms. We can use other specialised explainer can be view in the [official shap page](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html), including <code> shap.Linear()</code>.\n",
    "\n",
    "__Global Interpretation__:\n",
    "\n",
    "In the demonstration above, we showed a break down for an individual. Now, let's look at what happens when we aggregate to the model level. Basically we waht to how what is driving the overall model performance (feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shap_values = explainer.shap_values(val_X.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plot for top 10.\n",
    "shap.summary_plot(shap_values[1], val_X.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is made of many dots, each dot has three characteristics:\n",
    "\n",
    "- Vertical location shows what feature it is depicting\n",
    "- Color shows whether that feature was high or low for that row of the dataset\n",
    "- Horizontal location shows whether the effect of that value caused a higher or lower prediction.\n",
    "\n",
    "For example, the point in the upper left is for an individual with few days at worm, reducing the prediction by 0.05.\n",
    "The plot visibily shows that:\n",
    "- The model ignored flag_document_14.\n",
    "- Higer values of days_birth caused higher predictions and lower values lower predictions\n",
    "\n",
    "According to SHAP the top four features are \n",
    "- days_birth\n",
    "- days_employed\n",
    "- days_in_publish\n",
    "- flag_document_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using kernel explainer\n",
    "# k_explainer = shap.KernelExplainer(model.predict_proba, train_X)\n",
    "# # Calculate Shap values\n",
    "# k_shap_values = k_explainer.shap_values(data_for_prediction)\n",
    "# shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Decision Tree\")\n",
    "tree_disp = PartialDependenceDisplay.from_estimator(model, val_X.head(50), [\"DAYS_BIRTH\", \"DAYS_EMPLOYED\"], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit_transform(data['AMT_INCOME_TOTAL'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Hybrid methods\n",
    "As mentioned, these are methods that transforms the data into a completely different vector space and bear little or no resemblance to the original data yet carry the same information. They are commonly referred to as dimentionalily reduction methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = mk.dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = saspy.SASsession(\n",
    "        cfgfile=mk.saspy_file_path,\n",
    "        cfgname=mk.saspy_cfgname\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.saslib(dataset1['lib_name'], path=dataset1['path'])\n",
    "df = sess.sd2df(dataset1['table_name'], libref=dataset1['lib_name'], method=\"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df.columns if col.lower().find(\"date\")>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df.columns if col.lower().find(\"exclusion\")>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[25:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGD Data Descrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/data_utils.py\n",
    "dataset2 = mk.dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = saspy.SASsession(\n",
    "        cfgfile=mk.saspy_file_path,\n",
    "        cfgname=mk.saspy_cfgname\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.saslib(dataset2['lib_name'], path=dataset2['path'])\n",
    "lgd_data = sess.sd2df(dataset2['table_name'], libref=dataset2['lib_name'], method=\"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = lgd_data.select_dtypes(include=np.number).columns.values\n",
    "categorical_columns = lgd_data.select_dtypes(include=['object', 'category']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encode Categorical variables. For now, lets used  TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_data_cat = encoder.fit_transform(lgd_data[categorical_columns], lgd_data['LGD_bad_ind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection\n",
    "Select the top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = lgd_data.copy()\n",
    "processed_data[categorical_columns] = lgd_data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = feature_selection.VarianceThreshold(threshold=0.0025)\n",
    "X_reduced = selector.fit_transform(processed_data.drop('LGD_bad_ind', axis=1), processed_data.LGD_bad_ind)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function get_support can be used to generate the list of features that were kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = selector.get_support(indices=True)\n",
    "selected_columns = processed_data.iloc[:,cols].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same approach for mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_feature_importance(X, y, metric, k=5):\n",
    "\n",
    "    selector = feature_selection.SelectKBest(metric)\n",
    "    X_reduced = selector.fit_transform(X, y)\n",
    "    cols = selector.get_support(indices=True)\n",
    "    selected_columns = processed_data.iloc[:,cols].columns.tolist()\n",
    "\n",
    "    return  selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_feature_importance(\n",
    "    processed_data.drop('LGD_bad_ind', axis=1).head(100).fillna(0), \n",
    "    processed_data.LGD_bad_ind.head(100), \n",
    "    metric=feature_selection.mutual_info_classif, \n",
    "    k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that 19 columns have been dropped. We can explore the dropped columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_selected_columns(selector, X, y):\n",
    "    cols = selector.get_support(indices=True)\n",
    "    selected_columns = X.iloc[:,cols].columns.tolist()\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = feature_selection.SelectPercentile(feature_selection.mutual_info_classif, percentile=25)\n",
    "X_reduced = selector.fit_transform(\n",
    "    processed_data.drop('LGD_bad_ind', axis=1).head(100).fillna(0), \n",
    "    processed_data.LGD_bad_ind.head(100)\n",
    "    )\n",
    "X_reduced.shape\n",
    "\n",
    "_get_selected_columns(\n",
    "    selector, \n",
    "    processed_data.drop('LGD_bad_ind', axis=1).head(100).fillna(0), \n",
    "    processed_data.LGD_bad_ind.head(100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = feature_selection.SelectKBest(feature_selection.f_classif, k=20)\n",
    "X_reduced = selector.fit_transform(\n",
    "    processed_data.drop('LGD_bad_ind', axis=1).head(100).fillna(0), \n",
    "    processed_data.LGD_bad_ind.head(100)\n",
    "    )\n",
    "\n",
    "X_reduced.shape\n",
    "\n",
    "_get_selected_columns(\n",
    "    selector, \n",
    "    processed_data.drop('LGD_bad_ind', axis=1).head(100).fillna(0), \n",
    "    processed_data.LGD_bad_ind.head(100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_data.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from optbinning import Scorecard, BinningProcess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lgd_data.pkl', 'wb') as f:\n",
    "    pickle.dump(lgd_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lgd_data.pkl', 'rb') as f:\n",
    "    lgd_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "lgd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    lgd_data.drop('LGD_bad_ind', axis=1), lgd_data.LGD_bad_ind, test_size=0.2, random_state=42, stratify=lgd_data.LGD_bad_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = [column.lower() for column in X_train.columns]\n",
    "X_test.columns = [column.lower() for column in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df_application_train.select_dtypes(include=['object', 'category']).columns.values\n",
    "numerical_features = df_application_train.select_dtypes(include=np.number).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Ignore deprecated warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set font scale and style\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix and class label\n",
    "cols_to_drop = ['naics_industry_cd']\n",
    "X, y = X_train.drop(cols_to_drop, axis = 1), y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation pipeline\n",
    "1. Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom classes\n",
    "%run ../src/data_utils.py\n",
    "%run ../src/imputer.py'\n",
    "%run ../src/transforms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 'LGD_bad_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'LGD_bad_ind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f55a25da613ac67f6a065c2d4cb270f12d53ae2a52e7add8c08563a4e32f1506"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('general': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
